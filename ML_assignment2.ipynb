{"cells":[{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport csv # to work on csv files\n# different classifiers tried\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.neural_network import MLPClassifier\nimport xgboost as xgb\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC, NuSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\n# to do datapreprocessing\nfrom sklearn import preprocessing \nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\n# to obtain confusion matrix and accuracy score\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\n# Any results you write to the current directory are saved as output.\n\n#reading the data\ndf = pd.read_csv('/kaggle/input/ee-769-assignment1/train.csv')\ndf1 = pd.read_csv('/kaggle/input/ee-769-assignment1/test.csv')\n\n#data preparation\ny_train = df.iloc[:,1]\ndf = df.drop(['Attrition'], axis=1)\n\n# MAPPING to convert categorical data to numerical data\nmapping = {'Male':0,'Female':1,'Travel_Rarely':0,'Travel_Frequently':1,'Non-Travel':2,\n           'Research & Development':0,'Sales':1,'Human Resources':2,'Marketing':3,'Other':4,'Yes':0,'No':1,\n           'Life Sciences':1,'Technical Degree':1,'Medical':2,\n           'Single':2,'Married':1,'Divorced':0,'Sales Executive':0,\n           'Research Director':1,'Laboratory Technician':7,'Manufacturing Director':3,\n           'Healthcare Representative':4,'Manager':5,'Research Scientist':6,'Sales Representative':8}\n           \nx_tr = df.applymap(lambda s: mapping.get(s) if s in mapping else s)\nx_tst= df1.applymap(lambda s: mapping.get(s) if s in mapping else s)            \n# x_tr = df.applymap(lambda s: mapping.get(s) if s in mapping else s)\n# x_tst= df1.applymap(lambda s: mapping.get(s) if s in mapping else s)\n\n#LABELENCODER to convert Categorical data\n\n# class MultiColumnLabelEncoder:\n#     def __init__(self,columns = None):\n#         self.columns = columns # array of column names to encode\n\n#     def fit(self,X,y=None):\n#         return self # not relevant here\n\n#     def transform(self,X):\n#         '''\n#         Transforms columns of X specified in self.columns using\n#         LabelEncoder(). If no columns specified, transforms all\n#         columns in X.\n#         '''\n#         output = X.copy()\n#         if self.columns is not None:\n#             for col in self.columns:\n#                 output[col] = LabelEncoder().fit_transform(output[col])\n#         else:\n#             for colname,col in output.iteritems():\n#                 output[colname] = LabelEncoder().fit_transform(col)\n#         return output\n\n#     def fit_transform(self,X,y=None):\n#         return self.fit(X,y).transform(X)\n# x_tst = MultiColumnLabelEncoder(columns = [\"JobRole\",\"MaritalStatus\",\"DistanceFromHome\",\"BusinessTravel\",\"Department\",\"EducationField\",\"Gender\",\"OverTime\"]).fit_transform(df1)\n# x_tr = MultiColumnLabelEncoder(columns = [\"JobRole\",\"MaritalStatus\",\"DistanceFromHome\",\"BusinessTravel\",\"Department\",\"EducationField\",\"Gender\",\"OverTime\"]).fit_transform(df)\n\n # NORMALIZATION\n# x = x_tst.values #returns a numpy array\n# min_max_scaler = preprocessing.MinMaxScaler()\n# x_scaled = min_max_scaler.fit_transform(x)\n# x_tst = pd.DataFrame(x_scaled)\n# x = x_tr.values\n# x_scaled = min_max_scaler.fit_transform(x)\n# x_tr = pd.DataFrame(x_scaled)\n\n#dropping the columns which aren't really features\nx_tr = x_tr.drop(['EmployeeNumber','EmployeeCount','ID'],axis = 1)\nx_tst = x_tst.drop(['EmployeeNumber','EmployeeCount','ID'],axis = 1)\n\ni = 0\nclassifiers = [GradientBoostingClassifier()]\n#                , xgb.XGBClassifier(), AdaBoostClassifier()]    \n#     SVC(kernel=\"rbf\", C=0.025, probability=True), xgb.XGBClassifier()\n# #    NuSVC(probability=True),\n#     DecisionTreeClassifier(),\n#     RandomForestClassifier(),\n#     AdaBoostClassifier(),\n#     GradientBoostingClassifier(),\n#     GaussianNB(),\n#     LinearDiscriminantAnalysis(),\n#     QuadraticDiscriminantAnalysis()]\n   \nfor clf in classifiers:\n   clf.fit(x_tr, y_train)\n   name = clf.__class__.__name__\n   print(\"=\"*30)\n   print(name)\n   j = clf.predict(x_tst)\n   y_test = pd.DataFrame({'ID': df1.iloc[:,32], 'Attrition':j})\n   y_test.to_csv(r'/kaggle/working/sample_test_' + str(i) + '.csv',index=False, quoting=csv.QUOTE_NONNUMERIC, header=True)\n   i = i + 1\nprint(\"=\"*30)\n\n#CONFUSION MATRIX And Accuracy score\n# for clf in classifiers:\n#     clf.fit(x_tr, y_train)\n#     y_pred = clf.predict(x_tst)\n#     acc = accuracy_score(y_test, y_pred)\n#     print(\"Accuracy of %s is %s\"%(clf, acc))\n#     # cm = confusion_matrix(y_test, y_pred)\n#     # print(\"Confusion Matrix of %s is %s\"%(clf, cm))\n\n","execution_count":1,"outputs":[{"output_type":"stream","text":"==============================\nGradientBoostingClassifier\n==============================\n","name":"stdout"}]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":4}